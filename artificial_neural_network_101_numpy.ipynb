{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([0.765,0.838,0.329,0.277,0.45,0.833,0.44,0.634,0.351,0.784,0.589,0.816,0.352,0.591,0.04,0.38,0.816,0.732,0.32,0.597,0.908,0.146,0.691,0.75,0.568,0.866,0.705,0.027,0.607,0.793,0.864,0.057,0.877,0.164,0.729,0.291,0.324,0.745,0.158,0.098,0.113,0.794,0.452,0.765,0.983,0.001,0.474,0.773,0.155,0.875,])\n",
    "Y_test = np.array([6.322,6.254,3.224,2.87,4.177,6.267,4.088,5.737,3.379,6.334,5.381,6.306,3.389,5.4,1.704,3.602,6.306,6.254,3.157,5.446,5.918,2.147,6.088,6.298,5.204,6.147,6.153,1.653,5.527,6.332,6.156,1.766,6.098,2.236,6.244,2.96,3.183,6.287,2.205,1.934,1.996,6.331,4.188,6.322,5.368,1.561,4.383,6.33,2.192,6.108,])\n",
    "X_train = np.array([0.329,0.528,0.323,0.952,0.868,0.931,0.69,0.112,0.574,0.421,0.972,0.715,0.7,0.58,0.69,0.163,0.093,0.695,0.493,0.243,0.928,0.409,0.619,0.011,0.218,0.647,0.499,0.354,0.064,0.571,0.836,0.068,0.451,0.074,0.158,0.571,0.754,0.259,0.035,0.595,0.245,0.929,0.546,0.901,0.822,0.797,0.089,0.924,0.903,0.334,])\n",
    "Y_train = np.array([3.221,4.858,3.176,5.617,6.141,5.769,6.081,1.995,5.259,3.932,5.458,6.193,6.129,5.305,6.081,2.228,1.912,6.106,4.547,2.665,5.791,3.829,5.619,1.598,2.518,5.826,4.603,3.405,1.794,5.23,6.26,1.81,4.18,1.832,2.208,5.234,6.306,2.759,1.684,5.432,2.673,5.781,5.019,5.965,6.295,6.329,1.894,5.816,5.951,3.258,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_ARCHITECTURE = [\n",
    "    {\"input_dim\": 1, \"output_dim\": 8, \"activation\": \"relu\"},\n",
    "    {\"input_dim\": 8, \"output_dim\": 1, \"activation\": \"none\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(ann_architecture):\n",
    "   \n",
    "    # number of layers in our neural network\n",
    "    number_of_layers = len(ann_architecture)\n",
    "    \n",
    "    # parameters storage initiation\n",
    "    params_values = {}\n",
    "    \n",
    "    # iteration over network layers\n",
    "    for idx, layer in enumerate(ann_architecture):\n",
    "        # we number network layers from 1\n",
    "        layer_idx = idx + 1\n",
    "        \n",
    "        # extracting the number of units in layers\n",
    "        layer_input_size = layer[\"input_dim\"]\n",
    "        layer_output_size = layer[\"output_dim\"]\n",
    "        \n",
    "        # initiating the values of the W matrix\n",
    "        # and vector b for subsequent layers\n",
    "        params_values['W' + str(layer_idx)] = np.random.randn(\n",
    "            layer_output_size, layer_input_size) * 0.1\n",
    "        params_values['b' + str(layer_idx)] = np.random.randn(\n",
    "            layer_output_size, 1) * 0.1\n",
    "        \n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0,Z)\n",
    "\n",
    "def sigmoid_backward(dA, Z):\n",
    "    sig = sigmoid(Z)\n",
    "    return dA * sig * (1 - sig)\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0] = 0;\n",
    "    return dZ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single layer forward propagation step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\boldsymbol{Z}^{[l]} = \\boldsymbol{W}^{[l]} \\cdot \\boldsymbol{A}^{[l-1]} + \\boldsymbol{b}^{[l]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\boldsymbol{A}^{[l]} = g^{[l]}(\\boldsymbol{Z}^{[l]})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer_forward_propagation(A_prev, W_curr, b_curr, activation):\n",
    "    \n",
    "    # calculation of the input value for the activation function\n",
    "    Z_curr = np.dot(W_curr, A_prev) + b_curr\n",
    "    \n",
    "    # selection of activation function\n",
    "    if activation is \"none\":\n",
    "        return Z_curr, Z_curr\n",
    "    elif activation is \"relu\":\n",
    "        activation_func = relu\n",
    "    elif activation is \"sigmoid\":\n",
    "        activation_func = sigmoid\n",
    "    else:\n",
    "        raise Exception('Non-supported activation function')\n",
    "        \n",
    "    # return of calculated activation A and the intermediate Z matrix\n",
    "    return activation_func(Z_curr), Z_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_forward_propagation(X, params_values, ann_architecture):\n",
    "    # creating a temporary memory to store the information needed for a backward step\n",
    "    memory = {}\n",
    "    # X vector is the activation for layer 0â€Š\n",
    "    A_curr = X\n",
    "    \n",
    "    # iteration over network layers\n",
    "    for idx, layer in enumerate(ann_architecture):\n",
    "        # we number network layers from 1\n",
    "        layer_idx = idx + 1\n",
    "        # transfer the activation from the previous iteration\n",
    "        A_prev = A_curr\n",
    "        \n",
    "        # extraction of the activation function for the current layer\n",
    "        activ_function_curr = layer[\"activation\"]\n",
    "        \n",
    "        # extraction of W for the current layer\n",
    "        W_curr = params_values[\"W\" + str(layer_idx)]\n",
    "        # extraction of b for the current layer\n",
    "        b_curr = params_values[\"b\" + str(layer_idx)]\n",
    "        # calculation of activation for the current layer\n",
    "        A_curr, Z_curr = single_layer_forward_propagation(A_prev, W_curr, b_curr, activ_function_curr)\n",
    "        \n",
    "        # saving calculated values in the memory\n",
    "        memory[\"A\" + str(idx)] = A_prev\n",
    "        memory[\"Z\" + str(layer_idx)] = Z_curr\n",
    "       \n",
    "    # return of prediction vector and a dictionary containing intermediate values\n",
    "    return A_curr, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost_value(Y_hat, Y):\n",
    "    cost = Y_hat - Y\n",
    "    return np.squeeze(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_layer_backward_propagation(dA_curr, W_curr, b_curr, Z_curr, A_prev, activation):\n",
    "    \n",
    "    # selection of activation function\n",
    "    if activation is \"none\":\n",
    "        backward_activation_func = relu_backward\n",
    "        \n",
    "        dZ_curr = dA_curr\n",
    "\n",
    "    else:\n",
    "        if activation is \"relu\":\n",
    "            backward_activation_func = relu_backward\n",
    "        elif activation is \"sigmoid\":\n",
    "            backward_activation_func = sigmoid_backward\n",
    "        else:\n",
    "            raise Exception('Non-supported activation function')\n",
    "        \n",
    "        # calculation of the activation function derivative\n",
    "        dZ_curr = backward_activation_func(dA_curr, Z_curr)\n",
    "\n",
    "    # derivative of the matrix W\n",
    "    dW_curr = np.dot(dZ_curr, A_prev.T)\n",
    "    \n",
    "    # derivative of the vector b\n",
    "    db_curr = np.sum(dZ_curr, axis=1, keepdims=True)\n",
    "    \n",
    "    # derivative of the matrix A_prev\n",
    "    dA_prev = np.dot(W_curr.T, dZ_curr)\n",
    "\n",
    "    return dA_prev, dW_curr, db_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_backward_propagation(Y_hat, Y, memory, params_values, ann_architecture):\n",
    "    \n",
    "    grads_values = {}\n",
    "    \n",
    "    # number of examples\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    # a hack ensuring the same shape of the prediction vector and labels vector\n",
    "    Y = Y.reshape(Y_hat.shape)\n",
    "    \n",
    "    # initiation of gradient descent algorithm\n",
    "    dA_prev = Y_hat - Y\n",
    "    \n",
    "    for layer_idx_prev, layer in reversed(list(enumerate(ann_architecture))):\n",
    "        \n",
    "        # we number network layers from 1\n",
    "        layer_idx_curr = layer_idx_prev + 1\n",
    "        \n",
    "        # extraction of the activation function for the current layer\n",
    "        activ_function_curr = layer[\"activation\"]    \n",
    "        \n",
    "        dA_curr = dA_prev\n",
    "        \n",
    "        A_prev = memory[\"A\" + str(layer_idx_prev)]\n",
    "        Z_curr = memory[\"Z\" + str(layer_idx_curr)]\n",
    "        \n",
    "        W_curr = params_values[\"W\" + str(layer_idx_curr)]\n",
    "        b_curr = params_values[\"b\" + str(layer_idx_curr)]\n",
    "        \n",
    "        dA_prev, dW_curr, db_curr = single_layer_backward_propagation(\n",
    "            dA_curr, W_curr, b_curr, Z_curr, A_prev, activ_function_curr)\n",
    "        \n",
    "        grads_values[\"dW\" + str(layer_idx_curr)] = dW_curr\n",
    "        grads_values[\"db\" + str(layer_idx_curr)] = db_curr\n",
    "    \n",
    "    return grads_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(params_values, grads_values, ann_architecture, learning_rate, m):\n",
    "\n",
    "    # iteration over network layers\n",
    "    for layer_idx, layer in enumerate(ann_architecture, 1):\n",
    "        params_values[\"W\" + str(layer_idx)] -= learning_rate * grads_values[\"dW\" + str(layer_idx)] / m     \n",
    "        params_values[\"b\" + str(layer_idx)] -= learning_rate * grads_values[\"db\" + str(layer_idx)] / m\n",
    "\n",
    "    return params_values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, ann_architecture, params_values, learning_rate, verbose=False, callback=None):\n",
    "    # initiation of neural net parameters\n",
    "    \n",
    "    # initiation of lists storing the history \n",
    "    # of metrics calculated during the learning process \n",
    "    cost_history = []\n",
    "    \n",
    "    # performing calculations for subsequent iterations\n",
    "    Y_hat, memory = full_forward_propagation(X, params_values, ann_architecture)\n",
    "        \n",
    "    # calculating metrics and saving them in history\n",
    "    cost = get_cost_value(Y_hat, Y)\n",
    "    cost_history.append(cost)\n",
    "       \n",
    "    # step backward - calculating gradient\n",
    "    grads_values = full_backward_propagation(Y_hat, Y, memory, params_values, ann_architecture)\n",
    "    \n",
    "    # updating model state\n",
    "    m = X.shape[0] # m is number of samples in the batch\n",
    "    params_values = update(params_values, grads_values, ann_architecture, learning_rate, m)\n",
    "        \n",
    "    return params_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape(Y_train.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "params_values = init_parameters(ANN_ARCHITECTURE)\n",
    "\n",
    "'''      \n",
    "for e in range(20000):\n",
    "    for i in range(50):\n",
    "        params_values = train(np.transpose(X_train[i:(i+1)*1]), \n",
    "                              np.transpose(Y_train[i:(i+1)*1]), \n",
    "                              ANN_ARCHITECTURE, params_values, 0.001)            \n",
    "'''\n",
    "\n",
    "# implementation of the stochastic gradient descent\n",
    "EPOCHS = 20000\n",
    "for epoch in range(EPOCHS):\n",
    "    samples_per_batch = 5\n",
    "    \n",
    "    for i in range(int(X_train.shape[0]/samples_per_batch)):\n",
    "        si = i * samples_per_batch\n",
    "        sj = (i + 1) * samples_per_batch\n",
    "\n",
    "        params_values = train(\n",
    "            np.transpose(X_train[si:sj]), \n",
    "            np.transpose(Y_train[si:sj]),\n",
    "            ANN_ARCHITECTURE, \n",
    "            params_values, \n",
    "            0.001) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "Y_train_hat, _ = full_forward_propagation(np.transpose(X_train), params_values, ANN_ARCHITECTURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013713920176913596"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy achieved on the test set\n",
    "cost_train = get_cost_value(Y_train_hat, np.transpose(Y_train.reshape((Y_train.shape[0], 1))))\n",
    "cost_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.49687033, 6.18681028, 3.46480874, 3.10318671, 4.30627537,\n",
       "        6.20858757, 4.23673267, 5.585861  , 3.61780267, 6.42200509,\n",
       "        5.27291886, 6.28263038, 3.62475694, 5.2868274 , 1.45502479,\n",
       "        3.81947649, 6.28263038, 6.26737943, 3.40222031, 5.32855302,\n",
       "        5.88192811, 2.19217738, 5.98225437, 6.39255628, 5.1268792 ,\n",
       "        6.06485741, 6.07961415, 1.36461929, 5.39809571, 6.38280595,\n",
       "        6.07356833, 1.57324738, 6.01694735, 2.31735424, 6.24651662,\n",
       "        3.20054649, 3.43003739, 6.35778493, 2.27562862, 1.85837244,\n",
       "        1.96268648, 6.37845049, 4.32018391, 6.49687033, 5.55621112,\n",
       "        1.18380828, 4.47317784, 6.46991514, 2.25476581, 6.02565827]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 1)\n",
    "Y_test_predicted, _ = full_forward_propagation(np.transpose(X_test), params_values, ANN_ARCHITECTURE)\n",
    "Y_test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.17685401, 2.56770795, 3.95856189, 5.34941583, 6.35231774,\n",
       "        5.48370201]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([0., 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "X_new = X_new.reshape(X_new.shape[0], 1)\n",
    "y_predicted, _ = full_forward_propagation(np.transpose(X_new), params_values, ANN_ARCHITECTURE)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display training data and predicted data graphically\n",
    "plt.title('Training data (green color) + Predicted data (red color)')\n",
    "\n",
    "# training data in green color\n",
    "plt.scatter(X_train, Y_train, color='green',  alpha=0.5)\n",
    "\n",
    "# training data in green color\n",
    "#plt.scatter(X_test, Y_test_predicted, color='blue',  alpha=0.5)\n",
    "\n",
    "# predicted data in blue color\n",
    "plt.scatter(X_new, y_predicted, color='red',  alpha=0.5)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
